# ==============================================================================
# GGUF CONFIGURATION for Smart-Secrets-Scanner
# ==============================================================================
# Configuration for converting merged models to GGUF format
# Optimized for Smart-Secrets-Scanner secret detection model

model:
  # Merged model path (relative to project root)
  merged_path: "models/merged/smart-secrets-scanner"

  # GGUF output directory (relative to project root)
  gguf_output_dir: "models/fine-tuned/gguf"

  # Model name for GGUF files
  gguf_model_name: "smart-secrets-scanner"

quantization:
  # Default quantization types to create
  default_types: ["Q4_K_M"]

  # Use CUDA acceleration for conversion (if available)
  use_cuda: true

# Safety and validation
safety:
  # Run GGUF verification after conversion
  verify_gguf: true

  # Allow overwriting existing files
  force_overwrite: false