{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4164d0",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "## Smart Secrets Scanner - Training Dataset Analysis\n",
    "\n",
    "**Purpose:** Explore, validate, and visualize the training dataset for the Smart Secrets Scanner fine-tuned model.\n",
    "\n",
    "**Dataset:** v3 (1000 examples - 500 ALERT + 500 SAFE)\n",
    "\n",
    "**Sections:**\n",
    "1. Introduction & Setup\n",
    "2. Load Training Data\n",
    "3. Data Quality Checks\n",
    "4. Class Balance Analysis\n",
    "5. Secret Type Distribution\n",
    "6. Sample Examples\n",
    "7. Token Length Analysis\n",
    "8. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0742aa",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "\n",
    "Import required libraries and configure paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38364bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "\n",
    "TRAIN_FILE = DATA_DIR / 'smart-secrets-scanner-train-v3.jsonl'\n",
    "VAL_FILE = DATA_DIR / 'smart-secrets-scanner-val-v3.jsonl'\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Training File: {TRAIN_FILE}\")\n",
    "print(f\"Validation File: {VAL_FILE}\")\n",
    "print(f\"\\nTrain file exists: {TRAIN_FILE.exists()}\")\n",
    "print(f\"Val file exists: {VAL_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d52a818",
   "metadata": {},
   "source": [
    "## 2. Load Training Data\n",
    "\n",
    "Load JSONL files into pandas DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file into a list of dictionaries.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    train_data = load_jsonl(TRAIN_FILE)\n",
    "    val_data = load_jsonl(VAL_FILE)\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    val_df = pd.DataFrame(val_data)\n",
    "    \n",
    "    print(f\"‚úÖ Training data loaded: {len(train_df)} examples\")\n",
    "    print(f\"‚úÖ Validation data loaded: {len(val_df)} examples\")\n",
    "    print(f\"\\nTotal dataset size: {len(train_df) + len(val_df)} examples\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nPlease ensure you've generated the v3 dataset using:\")\n",
    "    print(\"  python scripts/generate_simple_training_data.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"Training Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_df.info())\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fcf34",
   "metadata": {},
   "source": [
    "## 3. Data Quality Checks\n",
    "\n",
    "Validate data schema, check for issues, and ensure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema validation\n",
    "required_fields = ['instruction', 'input', 'output']\n",
    "\n",
    "print(\"Schema Validation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for field in required_fields:\n",
    "    train_has = field in train_df.columns\n",
    "    val_has = field in val_df.columns\n",
    "    status = \"‚úÖ\" if (train_has and val_has) else \"‚ùå\"\n",
    "    print(f\"{status} Field '{field}': Train={train_has}, Val={val_has}\")\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nNull Values Check:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nValidation data:\")\n",
    "print(val_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348aba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for empty strings\n",
    "print(\"Empty String Check:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for field in required_fields:\n",
    "    train_empty = (train_df[field] == '').sum()\n",
    "    val_empty = (val_df[field] == '').sum()\n",
    "    print(f\"Field '{field}': Train={train_empty}, Val={val_empty}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nDuplicate Check:\")\n",
    "print(\"=\" * 50)\n",
    "train_dupes = train_df.duplicated(subset=['input']).sum()\n",
    "val_dupes = val_df.duplicated(subset=['input']).sum()\n",
    "print(f\"Training duplicates (by input): {train_dupes}\")\n",
    "print(f\"Validation duplicates (by input): {val_dupes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d55702",
   "metadata": {},
   "source": [
    "## 4. Class Balance Analysis\n",
    "\n",
    "Analyze distribution of ALERT vs SAFE examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from output field\n",
    "def extract_label(output_text):\n",
    "    \"\"\"Extract ALERT or SAFE from output text.\"\"\"\n",
    "    if 'ALERT' in output_text.upper():\n",
    "        return 'ALERT'\n",
    "    elif 'SAFE' in output_text.upper():\n",
    "        return 'SAFE'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "train_df['label'] = train_df['output'].apply(extract_label)\n",
    "val_df['label'] = val_df['output'].apply(extract_label)\n",
    "\n",
    "# Count labels\n",
    "train_counts = train_df['label'].value_counts()\n",
    "val_counts = val_df['label'].value_counts()\n",
    "\n",
    "print(\"Training Set Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_counts)\n",
    "print(f\"\\nBalance: {train_counts.get('ALERT', 0) / len(train_df) * 100:.1f}% ALERT\")\n",
    "\n",
    "print(\"\\nValidation Set Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "print(val_counts)\n",
    "print(f\"\\nBalance: {val_counts.get('ALERT', 0) / len(val_df) * 100:.1f}% ALERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeffe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training set\n",
    "train_counts.plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Label')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(train_counts):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Validation set\n",
    "val_counts.plot(kind='bar', ax=axes[1], color=['#e74c3c', '#2ecc71'])\n",
    "axes[1].set_title('Validation Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Label')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(val_counts):\n",
    "    axes[1].text(i, v + 2, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset is {'balanced' if abs(train_counts['ALERT'] - train_counts['SAFE']) < 50 else 'imbalanced'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316e116",
   "metadata": {},
   "source": [
    "## 5. Secret Type Distribution\n",
    "\n",
    "Analyze what types of secrets appear in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a29b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract secret types from ALERT examples\n",
    "def extract_secret_type(text):\n",
    "    \"\"\"Extract secret type from input or output text.\"\"\"\n",
    "    text_upper = text.upper()\n",
    "    \n",
    "    # Define patterns to search for\n",
    "    patterns = {\n",
    "        'AWS': ['AWS', 'AKIA', 'ACCESS_KEY', 'SECRET_KEY'],\n",
    "        'Stripe': ['STRIPE', 'SK_LIVE', 'PK_LIVE'],\n",
    "        'GitHub': ['GITHUB', 'GHP_', 'GHSA_'],\n",
    "        'Database': ['DATABASE', 'DB_PASSWORD', 'POSTGRES', 'MYSQL'],\n",
    "        'API Key': ['API_KEY', 'APIKEY', 'API-KEY'],\n",
    "        'OAuth': ['OAUTH', 'CLIENT_SECRET', 'CLIENT_ID'],\n",
    "        'JWT': ['JWT', 'TOKEN', 'BEARER'],\n",
    "        'Firebase': ['FIREBASE', 'GOOGLE'],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    for secret_type, keywords in patterns.items():\n",
    "        if any(kw in text_upper for kw in keywords):\n",
    "            return secret_type\n",
    "    \n",
    "    return 'Other'\n",
    "\n",
    "# Extract types for ALERT examples only\n",
    "alert_examples = train_df[train_df['label'] == 'ALERT'].copy()\n",
    "alert_examples['secret_type'] = alert_examples.apply(\n",
    "    lambda row: extract_secret_type(row['input'] + ' ' + row['output']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "secret_type_counts = alert_examples['secret_type'].value_counts()\n",
    "\n",
    "print(\"Secret Type Distribution (ALERT examples):\")\n",
    "print(\"=\" * 50)\n",
    "print(secret_type_counts)\n",
    "print(f\"\\nTotal ALERT examples: {len(alert_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize secret types\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "secret_type_counts.plot(kind='barh', ax=ax, color='#3498db')\n",
    "ax.set_title('Secret Type Distribution in Training Data', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Secret Type')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(secret_type_counts):\n",
    "    ax.text(v + 2, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df4ed0",
   "metadata": {},
   "source": [
    "## 6. Sample Examples\n",
    "\n",
    "Display representative examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77febf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ALERT examples\n",
    "print(\"Sample ALERT Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "alert_samples = train_df[train_df['label'] == 'ALERT'].sample(3, random_state=42)\n",
    "\n",
    "for idx, row in alert_samples.iterrows():\n",
    "    print(f\"\\nExample {idx + 1}:\")\n",
    "    print(f\"Input: {row['input'][:100]}...\")\n",
    "    print(f\"Output: {row['output'][:150]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SAFE examples\n",
    "print(\"Sample SAFE Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "safe_samples = train_df[train_df['label'] == 'SAFE'].sample(3, random_state=42)\n",
    "\n",
    "for idx, row in safe_samples.iterrows():\n",
    "    print(f\"\\nExample {idx + 1}:\")\n",
    "    print(f\"Input: {row['input'][:100]}...\")\n",
    "    print(f\"Output: {row['output'][:150]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af86b1",
   "metadata": {},
   "source": [
    "## 7. Token Length Analysis\n",
    "\n",
    "Analyze the length distribution of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c53fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate character lengths (rough proxy for tokens)\n",
    "train_df['input_length'] = train_df['input'].str.len()\n",
    "train_df['output_length'] = train_df['output'].str.len()\n",
    "train_df['total_length'] = train_df['input_length'] + train_df['output_length']\n",
    "\n",
    "# Statistics\n",
    "print(\"Input Length Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_df['input_length'].describe())\n",
    "\n",
    "print(\"\\nOutput Length Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_df['output_length'].describe())\n",
    "\n",
    "print(\"\\nTotal Length Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(train_df['total_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize length distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Input length distribution\n",
    "axes[0, 0].hist(train_df['input_length'], bins=30, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Input Length Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Characters')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Output length distribution\n",
    "axes[0, 1].hist(train_df['output_length'], bins=30, color='#2ecc71', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Output Length Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Characters')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Total length distribution\n",
    "axes[1, 0].hist(train_df['total_length'], bins=30, color='#e74c3c', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Total Length Distribution (Input + Output)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Characters')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Length by label\n",
    "train_df.boxplot(column='total_length', by='label', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Total Length by Label', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Label')\n",
    "axes[1, 1].set_ylabel('Total Characters')\n",
    "plt.sca(axes[1, 1])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0cca88",
   "metadata": {},
   "source": [
    "## 8. Summary & Recommendations\n",
    "\n",
    "Summary of findings and recommendations for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad960f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"Dataset Summary Report\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Size:\")\n",
    "print(f\"   - Training examples: {len(train_df)}\")\n",
    "print(f\"   - Validation examples: {len(val_df)}\")\n",
    "print(f\"   - Total: {len(train_df) + len(val_df)}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  Class Balance:\")\n",
    "print(f\"   - Training ALERT: {train_counts.get('ALERT', 0)} ({train_counts.get('ALERT', 0) / len(train_df) * 100:.1f}%)\")\n",
    "print(f\"   - Training SAFE: {train_counts.get('SAFE', 0)} ({train_counts.get('SAFE', 0) / len(train_df) * 100:.1f}%)\")\n",
    "balance_status = \"‚úÖ Balanced\" if abs(train_counts.get('ALERT', 0) - train_counts.get('SAFE', 0)) < 50 else \"‚ö†Ô∏è Imbalanced\"\n",
    "print(f\"   - Status: {balance_status}\")\n",
    "\n",
    "print(f\"\\nüîç Data Quality:\")\n",
    "quality_checks = [\n",
    "    (\"Schema validation\", all(f in train_df.columns for f in required_fields)),\n",
    "    (\"No null values\", train_df.isnull().sum().sum() == 0),\n",
    "    (\"No empty strings\", all((train_df[f] != '').all() for f in required_fields)),\n",
    "    (\"No duplicates\", train_df.duplicated(subset=['input']).sum() == 0)\n",
    "]\n",
    "\n",
    "for check_name, passed in quality_checks:\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"   {status} {check_name}\")\n",
    "\n",
    "print(f\"\\nüìè Length Statistics:\")\n",
    "print(f\"   - Avg input length: {train_df['input_length'].mean():.0f} chars\")\n",
    "print(f\"   - Avg output length: {train_df['output_length'].mean():.0f} chars\")\n",
    "print(f\"   - Max total length: {train_df['total_length'].max()} chars (~{train_df['total_length'].max() / 4:.0f} tokens)\")\n",
    "\n",
    "print(f\"\\nüéØ Secret Type Coverage:\")\n",
    "for secret_type, count in secret_type_counts.head(5).items():\n",
    "    print(f\"   - {secret_type}: {count} examples\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "print(f\"   ‚úÖ Dataset size (1000 examples) is good for fine-tuning\")\n",
    "print(f\"   ‚úÖ 80/20 train/val split is appropriate\")\n",
    "if balance_status == \"‚úÖ Balanced\":\n",
    "    print(f\"   ‚úÖ Class balance is excellent for binary classification\")\n",
    "print(f\"   ‚úÖ Diverse secret types will improve model generalization\")\n",
    "print(f\"   ‚úÖ Ready to proceed with fine-tuning!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Next Steps: Proceed to notebook 02_fine_tuning_interactive.ipynb\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
