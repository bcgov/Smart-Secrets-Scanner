# Task: Run Inference on Fine-Tuned Model

**Status: Backlog**

## Prerequisites (Completed)

âœ… **Task 01-05**: Environment setup (WSL2, NVIDIA, ML-Env-CUDA13, dependencies)  
âœ… **Task 22**: Base model downloaded  
âœ… **Task 37**: Inference script created (`scripts/inference.py`) âœ…  

**Pending:**  
â³ **Task 08**: Fine-tuning Iteration 4 (in-progress - need trained model)  

## Description
Test the fine-tuned model by running inference on a sample input.

**ğŸ”— Implemented by Task 37: Create Inference Python Script**

See `tasks/done/37-create-inference-python-script.md` for the complete implementation of `scripts/inference.py`.

## Steps
- Activate ML-Env-CUDA13 Python environment
- Run the provided infer.sh script or equivalent Python command
- Review generated output

## Resources
- Project README: infer.sh script
